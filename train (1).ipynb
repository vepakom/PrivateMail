{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /Users/vepakommac/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ac975a32734ad5a9f8924bc96fa1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3335c46c046d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;31m# model setup, model profile, optimizer config and loss definition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackbone_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgd_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_to_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0mflops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0mflops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclever_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mflops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from thop import profile, clever_format\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model import Model, set_bn_eval\n",
    "from utils import recall, LabelSmoothingCrossEntropyLoss, BatchHardTripletLoss, ImageReader, MPerClassSampler\n",
    "\n",
    "dev = torch.device(\"cuda:0\")  \n",
    "\n",
    "def train(net, optim):\n",
    "    torch.cuda.empty_cache()\n",
    "    net.train()\n",
    "    # fix bn on backbone network\n",
    "    net.apply(set_bn_eval)\n",
    "    total_loss, total_correct, total_num, data_bar = 0, 0, 0, tqdm(train_data_loader)\n",
    "    for i, (inputs, labels) in enumerate(data_bar):\n",
    "        #if i > 5000:\n",
    "        #    break\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        features, classes = net(inputs)\n",
    "        class_loss = class_criterion(classes, labels)\n",
    "        feature_loss = feature_criterion(features, labels)\n",
    "        loss = class_loss + feature_loss\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        pred = torch.argmax(classes, dim=-1)\n",
    "        total_loss += loss.item() * inputs.size(0)\n",
    "        total_correct += torch.sum(pred == labels).item()\n",
    "        total_num += inputs.size(0)\n",
    "        data_bar.set_description('Train Epoch {}/{} - Loss:{:.4f} - Acc:{:.2f}%'\n",
    "                                 .format(epoch, num_epochs, total_loss / total_num, total_correct / total_num * 100))\n",
    "\n",
    "    return total_loss / total_num, total_correct / total_num * 100\n",
    "\n",
    "\n",
    "def test(net, recall_ids):\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        # obtain feature vectors for all data\n",
    "        for key in eval_dict.keys():\n",
    "            eval_dict[key]['features'] = []\n",
    "            for inputs, labels in tqdm(eval_dict[key]['data_loader'], desc='processing {} data'.format(key)):\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                features, classes = net(inputs)\n",
    "                eval_dict[key]['features'].append(features)\n",
    "            eval_dict[key]['features'] = torch.cat(eval_dict[key]['features'], dim=0)\n",
    "\n",
    "        # compute recall metric\n",
    "        if data_name == 'isc':\n",
    "            acc_list = recall(eval_dict['test']['features'], test_data_set.labels, recall_ids,\n",
    "                              eval_dict['gallery']['features'], gallery_data_set.labels)\n",
    "        else:\n",
    "            acc_list = recall(eval_dict['test']['features'], test_data_set.labels, recall_ids)\n",
    "    desc = 'Test Epoch {}/{} '.format(epoch, num_epochs)\n",
    "    for index, rank_id in enumerate(recall_ids):\n",
    "        desc += 'R@{}:{:.2f}% '.format(rank_id, acc_list[index] * 100)\n",
    "        results['test_recall@{}'.format(rank_id)].append(acc_list[index] * 100)\n",
    "    print(desc)\n",
    "    return acc_list[0]\n",
    "\n",
    "\n",
    "'''\n",
    "parser = argparse.ArgumentParser(description='Train CGD')\n",
    "parser.add_argument('--data_path', default='/home/data', type=str, help='datasets path')\n",
    "parser.add_argument('--data_name', default='car', type=str, choices=['car', 'cub', 'sop', 'isc'],\n",
    "                    help='dataset name')\n",
    "parser.add_argument('--crop_type', default='uncropped', type=str, choices=['uncropped', 'cropped'],\n",
    "                    help='crop data or not, it only works for car or cub dataset')\n",
    "parser.add_argument('--backbone_type', default='resnet50', type=str, choices=['resnet50', 'resnext50'],\n",
    "                    help='backbone network type')\n",
    "parser.add_argument('--gd_config', default='SG', type=str,\n",
    "                    choices=['S', 'M', 'G', 'SM', 'MS', 'SG', 'GS', 'MG', 'GM', 'SMG', 'MSG', 'GSM'],\n",
    "                    help='global descriptors config')\n",
    "parser.add_argument('--feature_dim', default=1536, type=int, help='feature dim')\n",
    "parser.add_argument('--smoothing', default=0.1, type=float, help='smoothing value for label smoothing')\n",
    "parser.add_argument('--temperature', default=0.5, type=float,\n",
    "                    help='temperature scaling used in softmax cross-entropy loss')\n",
    "parser.add_argument('--margin', default=0.1, type=float, help='margin of m for triplet loss')\n",
    "parser.add_argument('--recalls', default='1,2,4,8', type=str, help='selected recall')\n",
    "parser.add_argument('--batch_size', default=128, type=int, help='train batch size')\n",
    "parser.add_argument('--num_epochs', default=20, type=int, help='train epoch number')\n",
    "\n",
    "opt = parser.parse_args()\n",
    "'''\n",
    "# args parse\n",
    "data_path, data_name, crop_type, backbone_type = ('/Users/vepakommac/Documents/PrivateMail/CGD-master/CUB_200_2011/CUB_200_2011', 'cub', 'cropped', 'resnet50')\n",
    "gd_config = 'G'\n",
    "feature_dim = 64\n",
    "smoothing, temperature  = (0.1, 0.5)\n",
    "margin = 0.1\n",
    "recalls = [1,2,4,8]\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "save_name_pre = '{}_{}_{}_{}_{}_{}_{}_{}_{}'.format(data_name, crop_type, backbone_type, gd_config, feature_dim,\n",
    "                                                    smoothing, temperature, margin, batch_size)\n",
    "\n",
    "results = {'train_loss': [], 'train_accuracy': []}\n",
    "for recall_id in recalls:\n",
    "    results['test_recall@{}'.format(recall_id)] = []\n",
    "\n",
    "# dataset loader\n",
    "train_data_set = ImageReader(data_path, data_name, 'train', crop_type)\n",
    "train_sample = MPerClassSampler(train_data_set.labels, batch_size)\n",
    "train_data_loader = DataLoader(train_data_set, batch_sampler=train_sample, num_workers=8)\n",
    "test_data_set = ImageReader(data_path, data_name, 'query' if data_name == 'isc' else 'test', crop_type)\n",
    "test_data_loader = DataLoader(test_data_set, batch_size, shuffle=False, num_workers=8)\n",
    "eval_dict = {'test': {'data_loader': test_data_loader}}\n",
    "if data_name == 'isc':\n",
    "    gallery_data_set = ImageReader(data_path, data_name, 'gallery', crop_type)\n",
    "    gallery_data_loader = DataLoader(gallery_data_set, batch_size, shuffle=False, num_workers=8)\n",
    "    eval_dict['gallery'] = {'data_loader': gallery_data_loader}\n",
    "\n",
    "# model setup, model profile, optimizer config and loss definition\n",
    "model = Model(backbone_type, gd_config, feature_dim, num_classes=len(train_data_set.class_to_idx)).cuda()\n",
    "flops, params = profile(model, inputs=(torch.randn(1, 3, 224, 224).cuda(),))\n",
    "flops, params = clever_format([flops, params])\n",
    "print('# Model Params: {} FLOPs: {}'.format(params, flops))\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "lr_scheduler = MultiStepLR(optimizer, milestones=[int(0.6 * num_epochs), int(0.8 * num_epochs)], gamma=0.1)\n",
    "class_criterion = LabelSmoothingCrossEntropyLoss(smoothing=smoothing, temperature=temperature)\n",
    "feature_criterion = BatchHardTripletLoss(margin=margin)\n",
    "\n",
    "best_recall = 0.0\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss, train_accuracy = train(model, optimizer)\n",
    "    results['train_loss'].append(train_loss)\n",
    "    results['train_accuracy'].append(train_accuracy)\n",
    "    rank = test(model, recalls)\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    # save statistics\n",
    "    data_frame = pd.DataFrame(data=results, index=range(1, epoch + 1))\n",
    "    data_frame.to_csv('results/{}_statistics.csv'.format(save_name_pre), index_label='epoch')\n",
    "    # save database and model\n",
    "    data_base = {}\n",
    "    if rank > best_recall:\n",
    "        best_recall = rank\n",
    "        data_base['test_images'] = test_data_set.images\n",
    "        data_base['test_labels'] = test_data_set.labels\n",
    "        data_base['test_features'] = eval_dict['test']['features']\n",
    "        if data_name == 'isc':\n",
    "            data_base['gallery_images'] = gallery_data_set.images\n",
    "            data_base['gallery_labels'] = gallery_data_set.labels\n",
    "            data_base['gallery_features'] = eval_dict['gallery']['features']\n",
    "        torch.save(model.state_dict(), 'results/{}_model.pth'.format(save_name_pre))\n",
    "        torch.save(data_base, 'results/{}_data_base.pth'.format(save_name_pre))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: thop in /Users/vepakommac/opt/anaconda3/lib/python3.7/site-packages (0.0.31.post2005241907)\n",
      "Requirement already satisfied: torch>=1.0.0 in /Users/vepakommac/opt/anaconda3/lib/python3.7/site-packages (from thop) (1.7.0)\n",
      "Requirement already satisfied: future in /Users/vepakommac/opt/anaconda3/lib/python3.7/site-packages (from torch>=1.0.0->thop) (0.18.2)\n",
      "Requirement already satisfied: typing_extensions in /Users/vepakommac/opt/anaconda3/lib/python3.7/site-packages (from torch>=1.0.0->thop) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in /Users/vepakommac/opt/anaconda3/lib/python3.7/site-packages (from torch>=1.0.0->thop) (0.6)\n",
      "Requirement already satisfied: numpy in /Users/vepakommac/opt/anaconda3/lib/python3.7/site-packages (from torch>=1.0.0->thop) (1.19.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install thop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
